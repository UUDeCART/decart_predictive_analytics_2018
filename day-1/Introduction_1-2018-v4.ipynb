{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECART Predictive Analytics: Day 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### _“Prediction is very difficult, especially about the future.”_  -Niels Bohr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Overview and Outline\n",
    "\n",
    "In this part, we will cover main *** concepts and essential theoretical background *** for predictive modeling cores and techniques. Most of these concepts are ** implemented in Python as modules, ** such that if each module is needed at any time, it will be easy to call instead of replicating it. In that regards, each code and concept will be introduced, discussed, and tested. \n",
    "\n",
    "We'll have about 6 heath care analytics use cases over our four days together. You will have 4 folders for 4 days.  For some days there will be some Python source code in a .py file that goes with notebooks. \n",
    "\n",
    "We'll try to cover all content in discussions or by way of exercises.  Predictive analytics is a very broad and multidisciplinary domain.  We don't claim to cover it comprehensively, here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTORS**  \n",
    "Samir Abdelrahman samir.abdelrahman@utah.edu  \n",
    "Lynd Bacon lynd.bacon@hsc.utah.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Topics and Objectives By Course Day \n",
    "1. Day 1:\n",
    "    - Introduction and challenges\n",
    "    - Quick review of the [pandas](http://pandas.pydata.org/) package for data science\n",
    "    - Regression with models linear in their parameters\n",
    "    - Introduction to Regression with Linear Models\n",
    "2. Day 2:\n",
    "    - Regression with Linear Models (cont.)\n",
    "    - Simple models for some limited dependent measures\n",
    "    - Regularization\n",
    "    - Bayesian regression, models with hyperparameters\n",
    "    - Cluster Analysis\n",
    "        - partitioning\n",
    "        - hierarchical\n",
    "        - model-based\n",
    "        - selecting the best number of clusters\n",
    "3. Day 3:\n",
    "    - Introduction\n",
    "        - Differences between classification and prediction\n",
    "        - Model development, validation, and testing\n",
    "        - Bias vs. variance and underfitting vs. overfitting\n",
    "        - Classification measures, like the F-measure, AUC, PPV, and NPV\n",
    "    - Classifiers\n",
    "        - Logistic regression, decision tree, support vector machine\n",
    "        - Ensemble methods\n",
    "        - binary, multi-class, multilabel classifiers\n",
    "4. Day 4:\n",
    "        - Classifiers (cont.)\n",
    "        - Introduction to Deep Learning\n",
    "            - Fully connected neural network\n",
    "            - Convolutional neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics (PA)\n",
    "\n",
    "PA is a multidisciplinary field that uses a combination of statistics and machine learning modeling techniques to predict unknow future events.\n",
    "\n",
    "<img src=\"../images/PA.png\" height= 75% width=75%>\n",
    "\n",
    "<sub>\n",
    "       Figure Reference: http://www.predictiveanalyticstoday.com/what-is-predictive-analytics/\n",
    "</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling (PM)\n",
    "PM usually is a combination of machine learning and/or simulation techniques to discover patterns from a given dataset of historical records/data points.\n",
    "\n",
    "<img src=\"../images/Datasets.png\" height= 70% width=70% style=\"float: center;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once models are developed, they may be \"embedded\" \\in running productional systems.  \n",
    "\n",
    "![Cook-Zubscek-JACR-2017-Fig-3.png](../images/Cook-Zubscek-JACR-2017-Fig-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validating results** is critically important in almost all ML/predictive analytics applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Machine Learning Algorithm Categories \n",
    "\n",
    "1. Supervised learning\n",
    "2. Unsupervised learning\n",
    "3. Semi-supervised learning\n",
    "4. Reinforcement learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Supervised Learning (Predictive learning)\n",
    "\n",
    "#### Key Idea:\n",
    "\n",
    "We have one or more observed dependent variables or _criterion_ measures to be predicted.  The data we have on what's to be predicted may be **[labeled data](https://en.wikipedia.org/wiki/Labeled_data)** about the subject, continuous data, or both. That is, we know some **truth** value or values, and we want to learn how to predict this truth value.  \n",
    "\n",
    "Generally speaking, we what to determine the best possible function of predictor variables, X, for predicting a dependent criterion, Y, one that minimizes prediction errors when generalized to a population of interest:  \n",
    "\n",
    "\\begin{align*}\n",
    "Y_i = f(X_i)+\\epsilon_i\n",
    "\\end{align*}\n",
    "\n",
    "We want to minimize the $\\epsilon_i$'s.\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. The goal is to infer a function from training data that relates values on observed outcome/criterion variables to values on variables that predict them.  \n",
    "\n",
    "\n",
    "2. Each training record is an example or a [vector of features/attributes](https://en.wikipedia.org/wiki/Feature_vector) (predictors) and label (outcome) variables.\n",
    "3. Once learned, the function can be used to make prediction for new cases, given that our function has been developed so as to _generalize_ adequately.\n",
    "\n",
    "## Types \n",
    "\n",
    "One way applications can be differentiated is in terms of the _nature of what's to predicted_.  In many cases, the variable to be predicted consists either of unordered categories, or of values on the real number line or a space with coordinates in $\\mathbf{R}$.  And then there are the \"in between\" cases.\n",
    "\n",
    "1. if Label is categorical, then classification. **(classification types?)**.\n",
    "    1. Male/Female\n",
    "    1. Student/Teacher\n",
    "    1. Malignant/Benign \n",
    "    1. Others?\n",
    "2. if Label is continuous on $\\mathbf{R}$, then regression.\n",
    "    1. Systolic blood pressure\n",
    "    1. BMI\n",
    "    1. serum creatinine\n",
    "    1. Others?\n",
    "3.  Not *strictly* unordered category labels, or values not spanning all of $\\mathbf{R}$. Some examples:  \n",
    "    1. Truncated values (e.g. at zero) on $\\mathbf{R}$\n",
    "    1. Counts\n",
    "    1. rankings\n",
    "    \n",
    "**QUESTION** \n",
    "\n",
    "Under circumstances might variables in category 2., above, need to be treated as if they are in category 3?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Challenges\n",
    "\n",
    "Most of the following pertain to ML/predictive analytics, in general.\n",
    "\n",
    "1. Enough training data.\n",
    "    1. Labeling can be expensive!\n",
    "2. External datasets to validate.\n",
    "3. Skewed or unbalanced dependent/criterion measures, e.g. rare events\n",
    "4. Time and memory constraints.\n",
    "4. Choosing between models\n",
    "5. Striking the best possible *bias-variance* tradeoff: \n",
    "\n",
    "In the context of machine learning, _bias_ and _variance_ can have particular definitions:\n",
    "\n",
    "**BIAS** = error in approximating the \"true state of Nature,\" real processes or systems.\n",
    "\n",
    "**VARIANCE** = how much our approximation of $f(X_i),~\\hat{f}(X_i)$, varies when applied to samples from the same population.  \n",
    "\n",
    "In principle, we could minimize _both_ bias and variance with the \"best\" model and lots of data.  It's not that easy. unfortunately.  bias and variance usually vary in different ways as a given model is adjusted in various ways, e.g. by adding or modifying predictor variables. \n",
    "\n",
    "6. Alrogithmic bias\n",
    "7. Algorithm aversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# _Unsupervised_ Learning\n",
    "\n",
    "\n",
    "#### Key idea\n",
    "\n",
    "**Labels or values** that help us understand the observations we have data for _are not available_. For example, we might want to know if the observations can be summarized as falling into different groups.  We want use machine learning to *infer* labels or values.\n",
    "\n",
    "##  Approach\n",
    "\n",
    "1. Generally speaking, it's task of inferring a similarity function from unlabeled training data to partition the dataset into subgroups (subpopulations).\n",
    "2. Inferred labels could be used for measuring the performance of clusters.\n",
    "3. Inferred labels may be applied to new observations by applying a classifier.\n",
    "\n",
    "\n",
    "##  Types \n",
    "\n",
    "1. Discovering subpopulations (clustering).\n",
    "2. Discovering Frequent association and patterns among predictors (association/pattern mining).\n",
    "3. Using visualization to explore the data and dimensionality reduction to represent predictors (visual analytics; \"human\" pattern detection)\n",
    "\n",
    "\n",
    "## Challenges\n",
    "\n",
    "1. Validation: quantitative vs qualitative also intra (in) cluster and inter (between) clusters.\n",
    "2. Identifying clusters with complex, multidimensional \"shapes\"\n",
    "2. Noise and outliers **(difference?)**.\n",
    "3. Time and memory constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning (SSL)\n",
    " \n",
    " ### What SSL Is\n",
    "1. Combines unsupervised and supervisor learning methods.\n",
    "2. Used when there aer many unlabeled observations and few labeled observations.\n",
    "3. There many versions with different orders of learning algorithms.  The aim is to boost the whole learning. \n",
    "\n",
    "### How it Works, in a \"Nutshell\"\n",
    "1. Use labeled seeds as initial examples for clustering.\n",
    "2. Run a clustering algorithm to associate unlabeled cases with the seeds. \n",
    "3. Repeat the above two steps to refine and redistribute the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice write-up of clustering and semi-supervised clustering methods: \n",
    "    \n",
    "[Semi-supervised clustering methods](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3979639/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reinforcement Learning (RL)\n",
    "\n",
    "1. A task that divides the learning algorithm into software \"agents\" that interacts with its environment in order to maximize some sort of award.\n",
    "2. Each agent monitors the environment and learn how to react, ignore, or set up new rules.\n",
    "3. An agent should run forever unless it is killed.\n",
    "\n",
    "<img src=\"../images/Agent.png\" height= 35% width=35% style=\"  right;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Thought Experiment: How might _you_ be an RL agent in real life?**\n",
    "\n",
    "\n",
    "<sub>\n",
    "       Agent Structure: https://en.wikipedia.org/wiki/Reinforcement_learning \n",
    "</sub>\n",
    "\n",
    "Richard Sutton and Andrew Barto wrote a seminal book about RL some years ago.  They have a draft of a new edition on line at:  \n",
    "\n",
    "[Reinforcement Learning: An Introduction, 2nd Ed.2018](https://drive.google.com/file/d/1xeUDVGWGUUv1-ccUMAZHJLej2C7aAFWY/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A Rumination Exercise\n",
    "\n",
    "Select one of following learning algorithms or methods: \n",
    "    * Supervised (classification/regression)\n",
    "    * Unsupervised (clustering/pattern mining)\n",
    "    * Semi-supervised\n",
    "    * Reinforcement Learning\n",
    "\n",
    "Then, describe how you might apply it to one of the following:\n",
    "    * predicting length of stay \n",
    "    * predicting mortality\n",
    "    * predicting chronic kidney disease\n",
    "    * Defining chronic kidney disease staging\n",
    "    * Integrating different data resources.\n",
    "    * Developing an interactive decision system used by both health care professionals and the patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
