{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course we use a number of Python packages to \"train,\" or fit, and evaluate various kinds of predictive models.  \n",
    "\n",
    "Current \"big hitter\" packages include [Scikit Learn](http://scikit-learn.org/stable/) and [StatsModels](http://www.statsmodels.org/stable/).  In the following exercise, we're going to use some methods provided in the latter to estimate and evaluate a simple linear regression model.  Our model predict a continuous dependent ('Y') variable using a weighted linear combination of predictor ('X') variables.  The weights, or regression coefficients, are unknown quantities that we want to estimate by specifying a model and using the available data.\n",
    "\n",
    "In other parts of this course we'll be using [Scikit Learn](http://scikit-learn.org/stable/) quite a bit.  \n",
    "\n",
    "[StatsModels](http://www.statsmodels.org/stable/) provide a very large number of statistical methods, as can be seen by perusing its [modules list](http://www.statsmodels.org/stable/py-modindex.html).\n",
    "\n",
    "In addition to using [StatsModels](http://www.statsmodels.org/stable/) methods, we'll use some other packages that are frequently used when using Python for data science.  \n",
    "\n",
    "What follows is a regression with Python \"warm-up,\" and probably also a linear regression review for many of you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# The following allows multiple outputs in a single output cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where you can learn about these packages:  \n",
    "* [Pandas](https://pandas.pydata.org)  \n",
    "* [Numpy](http://www.numpy.org)  \n",
    "* [matplotlib](https://matplotlib.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lesser known but often useful package for summarizing a pandas DataFrame is [pandas-profiling](https://github.com/pandas-profiling/pandas-profiling).  (Like any other Python package, it must be installed before it can be imported into a Python session.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will mute warnings that may be result from importing pandas-profiling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "# A risky thing to do, generally speaking. Remove if you're nervous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7e769dc468cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprofile\u001b[0m \u001b[0;31m# Note the_ (underscore), is not a - (dash).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas_profiling as profile # Note the_ (underscore), is not a - (dash).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.resetwarnings()  # Resets 'em to defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example data are responses to a satisfaction survey administered to patients at a community hospital.  The are in the file DECART-patSat.csv, a comma-delimited csv file with a header record of variable names.  \n",
    "\n",
    "The survey asked recently discharged inpatients to evaluate various aspects of their care experiences.  The aspects had been determined previously using qualitative research and with reference to the literature on patient satisfaction. Patients' perceptions on the aspects were captured on 11 points, 0 to 10 ratings scales.\n",
    "\n",
    "The variables in the file are:  \n",
    "\n",
    "| var name | item                 | rating scale  |\n",
    "| :--------| :--------------------| :-------------|\n",
    "| caseID   | respondent number    |  NA\n",
    "|   sat    | overall satisfaction | 1 = very dissat, 10 = very sat\n",
    "|   q2     | nurses listened      | 1 = never, 10 = always\n",
    "|   q3     | nurses explained     | 1 = never, 10 = always\n",
    "|   q4     | staff courteous      | 1 = never, 10 = always\n",
    "|   q5     | meals appetizing     | 1 = never, 10 = always\n",
    "|   q6     | doctors listened     | 1 = never, 10 = always\n",
    "|   q7     | doctors explained    | 1 = never, 10 = always\n",
    "|   q8     | staff responsive     | 1 = not at all, 10 = extremely\n",
    "|   q9     | room was comfortable | 1 = not at all, 10 = extremely\n",
    "| ptCat    | patient category     | 1= surg, 1 = med, 2 = concierge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using `sat` as our Y variable in our little example here, and the variables `q2`, `q6`, and `patCat` as our X's.   \n",
    "\n",
    "Let's input the data into a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSatDF=pd.read_csv('DECART-patSat.csv')  # Modify as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['caseID', 'patSat', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9',\n",
       "       'ptCat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "caseID    int64\n",
       "patSat    int64\n",
       "q2        int64\n",
       "q3        int64\n",
       "q4        int64\n",
       "q5        int64\n",
       "q6        int64\n",
       "q7        int64\n",
       "q8        int64\n",
       "q9        int64\n",
       "ptCat     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape, column names, and variable types of this DataFrame\n",
    "patSatDF.shape\n",
    "patSatDF.columns\n",
    "patSatDF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Look at The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab just the variables we want to use from what we input from the csv file, and then \"profile\" them for a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSatDF2=patSatDF[['patSat','q2','q6','ptCat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could view the profile report for this DataFrame here in Jupyter, but let's send it to an html file just in case it's length exceeds some limit here in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'profile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b139cf7d94d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpatSatProfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfileReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatSatDF2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpatSatProfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'patSatProfile.html'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To your current working dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'profile' is not defined"
     ]
    }
   ],
   "source": [
    "patSatProfile=profile.ProfileReport(patSatDF2)\n",
    "patSatProfile.to_file('patSatProfile.html')  # To your current working dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the html file using your browser.\n",
    "\n",
    "The variables `patSat` and `q2` through `q9` might be considered to be continuous measures with equal interval scales.  `ptCat` is not.  It's best considered to have unordered categories, an \"nominal\" measure.  We'll take this into account when we estimate a regression model, as follows.  \n",
    "\n",
    "Note that a usual exploratory data analysis (EDA) practice is to examine plots like scatterplots to discern unusual or unexpected data behavior.  We're going to forgo such EDA activities here.  Suffice it to say that the variables of interest have some dispersion.  (If they didn't, the couldn't be correlated with each other.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION:__ How else would you examine this data to discover features that you didn't expect, or that may inform you about models you may want to fit to it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's common machine learning practice to set aside a random subset of cases for use in checking for overfitting. Data sets that are \"large enough\" are usually split into \"train\" and \"test\" random subsamples.  The train subsample is used for model estimation, and the test subsample for assessing overfitting.   `scikit-learn` has methods for randomly splitting data. `Pandas` has ways of subsetting its data objects. But here we're going to use `numpy` and a bit of code to randomly split the cases in patSatDF2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)  # setting the seed just in case repeatability is needed.\n",
    "#patSatDF2.loc[:,'train']=pd.Series(np.random.random(len(patSatDF2))<=0.80)\n",
    "patSatDF2=patSatDF2.assign(train=pd.Series(np.random.random(len(patSatDF2))<=0.80))\n",
    "patSatTrain=patSatDF2[patSatDF2.train==True]\n",
    "patSatTest=patSatDF2[patSatDF2.train!=True]\n",
    "print('Number of train subsample number of records: ',len(patSatTrain))\n",
    "print('Number of test subsample number of records: ',len(patSatTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the model we're going estimate:\n",
    "\n",
    "$$\\large{{patSat_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 q2 + \\hat{\\beta}_2 q6 + \\hat{\\beta}_3ptCat_1+\\hat{\\beta}_4ptCat_2+\\hat{\\epsilon}_i}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model for each and every patient \"i.\"  It's linear in its parameters.  Note that there are _two_ predictor variables for `ptCat`.  This unordered categorical variable has three possible values, 0,1, and 2.  Hence we can only get two independent coefficient estimates for it.  There are two degrees of freedom, two df. \n",
    "\n",
    "The $\\hat{\\beta}$'s are the parameters to be estimated. $\\hat{\\beta}_{0}$ is a coefficient for an intercept term. $\\epsilon_i$ is estimated given the value of $patSat_i$ and the estimated value of the RHS before $\\epsilon_i$, the \"structural\" part of the RHS.\n",
    "\n",
    "\n",
    "The structure, or functional form, of this model implies particular assumptions that can be assessed given a particular set of data.  For example, the ${\\epsilon_{i}}'s$ are uncorrelated with the X variables.\n",
    "\n",
    "A common assumption is:\n",
    "\n",
    "$$\\large{{\\epsilon_{i} \\sim i.i.d. \\, N(0,\\sigma^{2}_{\\epsilon})}}$$\n",
    "\n",
    "The ${\\epsilon_i}'s$ are independently and identically distributed as Normal with mean zero and variance $\\sigma^{2}_{\\epsilon}$.  \n",
    "\n",
    "The assumptions are particularly important if you want to interpret the $\\hat{\\beta}$'s.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION:__ What other assumptions are indicated by this model's functional form?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate this model's parameters using the test subsample.  We'll use ordinary least squares, \"OLS,\" to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Estimation (\"Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, before we start OLS'ing, we need to specify how we're going to use those two df for the `patCat` categorical X variable.  We can get our two possible predictors of this variable for our regression equation in a couple of different ways.  \n",
    "\n",
    "[StatsModels](http://www.statsmodels.org/stable/contrasts.html?highlight=coding%20categorical) provides convenient ways to use some alternative methods for coding categorical variables.  Here we're going to use what `StatsModels` refers to as \"sum\" or \"deviation\" coding, by employing a method provided by the [Patsy](https://patsy.readthedocs.io/en/latest/) package.  This coding method is also referred to as \"effects\" coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION:__ Why must regression model categorical predictor variables be coded in some manner?\n",
    "\n",
    "__QUESTION:__ What other kinds of categorical variable coding are you familiar with? What kinds have you used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "`Patsy` also provides a means to express module equations like actual equations, similar to how equations can be expressed in the R programming environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how `Patsy` \"sum\" codes a three level categorical variable like `patCat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy.contrasts import Sum\n",
    "contrast = Sum().code_without_intercept(levels=[0,1,2])\n",
    "print(contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ptCat` X variable will have a column for each df.  If `ptCat` = 0 for a surg inpatient, the first column will be 1, and the second, 0.  If = 1, a med inpatient, the columns will be 0 and 1.  If `ptCat` is 2 for a concierge inpatient, both columns will be -1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit widens all cells in this Notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patSat ~ q2 + q6 + C(ptCat, Sum)\", data=patSatTrain)mod1 = smf.ols(\"patS\n",
    "mod1Result=mod1.fit()\n",
    "print(mod1Result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTIONS:__ \n",
    "\n",
    "* What assumptions are we making about the characteristics of the ratings measures?\n",
    "* What does the JB statistic measure?\n",
    "* What does the Durbin-Watson assess?\n",
    "* What does the condition number tell you?\n",
    "* What is the \"Omnibus?\"\n",
    "\n",
    "HINT: You can find out a lot about the statistics in `statsmodels` at: [statsmodels statistics](http://www.statsmodels.org/stable/stats.html)\n",
    "\n",
    "__Bonus Question:__ We effects coded ptCat and got two $\\beta$ coefficient estimates.  How could we estimate a coefficient for the omitted, or reference level, ptCat = 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip ahead for a bit to see how a model like this one can be used to predict the \"Test\" data, the data that weren't used for estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSat=mod1Result.predict(patSatTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the square of the Pearson correlation coefficient between the actual patSat values in the test data and the values predicted for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:5.3f}'.format(np.corrcoef(predSat,patSatTest.patSat)[0,1]**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION:__ When estimated $R^2$ is smaller when applied to a random subsample of data not used in estimating a model, what does it signify?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean-squared-error (MSE) is often used to describe the accuracy with which a model can reproduce what it's supposed to predict. It's also one of many model performance descriptions used in machine learning.  MSE can be using the model results obtained from a training subsample, or using model results obtained from training data applied to other data, data like our \"test\" data that we set aside, above.\n",
    "\n",
    "Ordinary least squares (OLS) estimation produces the smallest possible MSE of all estimation methods for the class of linear models.\n",
    "\n",
    "MSE is actually easy to compute.  Here it's also handily computed from model results and the variance of the dependent variable:\n",
    "\n",
    "\\begin{align*}\n",
    "MSE = (1-\\bar{R}^2)~{\\sigma_y}^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training data.  R2 is from the model results \n",
    "mseTrain=(1-0.634)*(np.var(patSatTrain.patSat))\n",
    "print('{:5.3f}'.format(mseTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the test data.  R2 is calculated, above.\n",
    "mseTest=(1-0.574)*(np.var(patSatTest.patSat))\n",
    "print('{:5.3f}'.format(mseTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE (Optional)** Create a simple Python function that accepts a Seris and an testimate of $R^2$, returns MSE based on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StatsModels` provides a large number of [diagnostic tools for regression modeling](http://www.statsmodels.org/devel/stats.html?highlight=correlation#module-statsmodels.stats.correlation_tools), and several built-in [diagnostic plots](http://www.statsmodels.org/dev/graphics.html?highlight=graphics#module-statsmodels.graphics).  \n",
    "\n",
    "The [seaborn](https://seaborn.pydata.org/) Python package for data visualization is sometimes easier to use. (At least for me, sometimes.)\n",
    "\n",
    "We'll take a look at using some of the methods from these two packages in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Variance Inflation Factor (VIF):__ VIFs provide more information about multicollinearity among the X variables than the condition number does.  \n",
    "\n",
    "The VIF of a predictor variable \"i\",  is:  \n",
    "\n",
    "$$\\large{VIF_i = \\frac{1}{1-{R_i}^2}}$$  \n",
    "\n",
    "where ${R_i}^2$ is the coefficient of determination from regressing the ith predictor variable on the remaining predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StatsModels` _doesn't_ provide a really convenient way to get the VIF's of all X variables at once, so a little coding is needed.  Here we use `patsy's` dmatrices method to get the X, or design matrix for our model.  Then we use `StatsModels`' method for getting the VIF for each X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "_, X = dmatrices('patSat~q2+q6+C(ptCat,Sum)',data=patSatTrain,return_type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at the X, or design, matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the VIFs for the intercept, the two coded categories of patCat, q2, and q6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF=[variance_inflation_factor(X.values,i) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join('{}: {:5.3f}'.format(*VIFi) for VIFi in enumerate(VIF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept appears to be closely approximated by a weighted linear combination of the other X variables. A VIF of 21 corresponds to an $R^2$ of about 0.95.  A commonly used heuristic is that VIF > 10 indicates serious multicollinearity.  Note the size of the condition number in the model summary, above.  A condition number > 30 is often taken to indicate severe multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that this `patsy` method will accept `mod1`'s 'exog' result instead of its reentered equation to do the above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIFagain=[variance_inflation_factor(X.values,i) for i in range(mod1.exog.shape[1])]  # another list of VIFs\n",
    "VIFagain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted patSat vs. Observed patSat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at how they are related using `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predObsDF=pd.DataFrame({'observed sat':patSatTrain.patSat,'predicted sat':mod1Result.predict(patSatTrain)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add to the graph a dotted line with a 45 deg. slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla\n",
    "sg=sns.jointplot(x=\"observed sat\", y=\"predicted sat\",marker=\"o\",data=predObsDF)\n",
    "x0, x1 = sg.ax_joint.get_xlim()\n",
    "y0, y1 = sg.ax_joint.get_ylim()\n",
    "lims = [max(x0, y0), min(x1, y1)]\n",
    "sg.ax_joint.plot(lims, lims, ':k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal QQPlot of Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use a `StatsModels` method to look into the assumption that the model residuals, the $\\epsilon_i\\'s, are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(mod1Result.resid, fit=True, line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION:__ What does this normal QQ plot indicate about the distribution of the $\\epsilon_i$'s?  \n",
    "\n",
    "TIP: Here's are some examples of normal QQ plots that show how variations from normal affect plot appearance [normal QQ Plot examples](https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Influence:__ An influential observation is one that is relatively extreme and whose removal noticeably changes model results. Influence measures like DFBeta, Cook's D, and others can be had using `StatsModels`'s methods. A summary of influence measures is also available, in a DataFrame, or in a table.  Here's a look at the DataFrame version for our OLS model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "influenceResults=OLSInfluence(mod1Result)\n",
    "influenceResults.summary_frame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StatsModels` has a several built-in plotting methods useful for diagnosing regression model issues.  They include influence and _leverage_ plot methods.  \n",
    "\n",
    "__Leverage:__ An observation with high leverage is one that's far away from other observations and that has a relatively large effect on parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.regressionplots import influence_plot\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "influence_plot(mod1Result,ax=ax,plot_alpha=0.01,alpha=0.001,fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers in the graph are the row numbers of cases that are high leverage or that have large residuals.  \n",
    "\n",
    "__QUESTION:__ Would you expect that a high leverage data point is associated with a relatively large residual, or a small residual?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a plot of the leverage _scores_ for the observations in the Train data versus their squared normalized residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod1Result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-59e7073fbe67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressionplots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_leverage_resid2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_leverage_resid2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod1Result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mod1Result' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "plot_leverage_resid2(mod1Result, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Else Would You Do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__QUESTION:__ What other graphs or descriptive summaries would you use to assess this model?  \n",
    "\n",
    "__QUESTION:__ What might you do to improve on this model?\n",
    "\n",
    "__QUESTION:__ How would you check for issues arising from 'endogeneity?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Those Regression Coefficient p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note from the summary output that there's a t-test for each regression coefficient that tests $H_0: \\beta=0$.  These are NHST's, of course, and the validity of conclusions based on them depends on whether the model is _approximately_ correct, whether key assumptions are tenable, and so on. \n",
    "\n",
    "### Question:\n",
    "\n",
    "Suppose one of the coefficients, say for q2, wasn't significantly different from zero based on this kind of NHST, while the coefficient for q6 was.  Would you say that the coefficients for q2 and q6 differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be moving on to other kinds of regression models, including some models for limited dependent variables, and models that can better cope with issues arising from multicollinearity.  But first we'll revisit bias and variance, and then we'll touch on what's called _regularization_.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
