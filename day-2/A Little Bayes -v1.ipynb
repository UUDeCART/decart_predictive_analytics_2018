{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for something different.\n",
    "\n",
    "Bayesian regression in a just a few minutes.\n",
    "\n",
    "Prediction problems can be approached using Bayesian methods.  Although methods for nontrivial \"learning\" (prediction) problems can be computationally intensive, continuing advances in algorithm and hardware development are making Bayesian applications feasible in an ever-widening array of contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been called the \"inverse probability\" theorem.  Attributed to the 18th century cleric Thomas Bayes, it's based on a principle of conditional probabilities:  \n",
    "\n",
    "\\begin{align*}\n",
    "\\large\n",
    "p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\n",
    "\\end{align*}  \n",
    "\n",
    "Here, A and B are events of some sort that may or may not occur. You can see where it came from by using the definition of a conditional probability:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\large {\n",
    "p(A~and~B) = p(A|B)p(B) \\\\\n",
    "P(B~and~A) = p(B|A)p(A) \\\\\n",
    "p(A~and~B) = p(B~and~A) \\\\\n",
    "p(A|B)p(B) = p(B|A)p(A) }\n",
    "\\end{align*}  \n",
    "\n",
    "\\begin{align*}\n",
    "\\large{\n",
    "p(A|B) = \\frac{p(B|A)}{p(B)} \\\\ }\n",
    "\\end{align*}  \n",
    "\n",
    "It's pretty simple.  In scientific applications, we use Greek letters to make it look more serious:  \n",
    "\n",
    "\\begin{align*}\n",
    "\\large\n",
    "p(\\theta|D)~=~\\frac{p(D|\\theta)p(\\theta)}{p(D)}\n",
    "\\end{align*}  \n",
    "\n",
    "Here, $\\theta$ is one or more parameters we want to learn about, and D is \"data,\" or information. $\\theta$ can be a very long vector. The term on the LHS is the posterior probability of $\\theta$ conditional on D; it tells us about uncertainty about $\\theta$.  The two quantities in the numerator on the RHS are referred to as the likelihood of the data given $\\theta$, and the prior probability of $\\theta$.  p(D) is often called the data density.  For a particular data set it's constant, so when estimating p($\\theta$|D) it's ignored, and the version of the above that's used is:  \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\large\n",
    "p(\\theta|D)~\\propto~p(D|\\theta)p(\\theta)\n",
    "\\end{align*} \n",
    "\n",
    "One way of looking at this theorem is that it is a _learning algorithm_.  p($\\theta$) is what we know about parameters of interest before getting D.  p(D|$\\theta$) is the likelihood of data we've observed given what we have believed about $\\theta$.  p($\\theta$|D) is how we've \"adjusted\" what we believe about $\\theta$ now that we've received D. p($\\theta$|D) can be our \"best guess\" about p($\\theta$) the next time we are about to get new D.  \n",
    "\n",
    "In any given Bayesian model, $\\theta$ may have many parameters, and p($\\theta$|D) may be highly dimensional.  Approximating p($\\theta$\\D) is the main objective of Bayesian modeling.  It's what we use to make inferences about $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION** Bayes Theorem is used in many different applications.  Can you think of any?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting an approximation of p($\\theta$|D) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most applications these days involve estimating many parameters, and estimating them cannot be done analytically, e.g. by solving equations.  For estimation purposes, stochastic simulation methods are typically used.  These procedures make use of the fact that the marginal posterior probability of a particular model parameter can be expressed as a function of the values of the other parameters and the data. So these methods repeatedly iterative over the parameters whose marginal posterior probabilities are to be estimated, ultimately resulting in an approximation to the joint posterior conditional density of the parameters.  These kinds of procedures are generally called _Markov Chain Monte Carlo_ (MCMC) simulation methods.  There are different kinds, and what's used depends on the characteristics of the probabilities to be estimated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specification and Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the basic steps used when estimating a Bayesian regression model.   In the following it's assumed that data are available, although you can specify a model before laying hands on data.  (You should, in fact.)  The simple application in what follows after this exemplifies what's described here.\n",
    "\n",
    "First, you specify a _full probability model_ that defines the relationships between variables, and the distributions of all parameters and functions of them.  This is one place where Bayesian methods differ from classical approaches.  Parameters have _hyperparameters_: parameters have parameters.  This part requires specifying _priors_ for parameters.\n",
    "\n",
    "Next, you select a _sampling method_ that is used iteratively to obtained values from the marginal conditional posterior of each parameter that is defined in your model specification. Samplers vary in terms of whether it's possible to directly evaluate (make a random draw) from marginal posterior distributions.  Commonly used samplers include the Gibbs sampler, the Metropolis sampler, and the Hamiltonian (\"NUTS\") sampler.\n",
    "\n",
    "Assuming that you have code that can run your sampler, you define initial values for each parameter, your $\\theta$ elements, and let your algorithm run.  Each iteration of it produces a \"draw,\" a value, from the posterior of each parameter. Based on a general theory, given that a model's parameter's are sufficiently identified in your specification, these \"chains\" or \"traces\" of parameter values generated by the iteration of the algorithm will \"settle in\" to be random draws from stable, conditional postierior parameter distributions. The iterations up until this occurs is usually called the \"burn-in\" for a MCMC run. The values obtained after the burn-in are used to estimate parameters and their uncertainties.  \n",
    "\n",
    "There's a lot more to this in the details, of course. But what's above is what it's about, in a nutshell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've approximated the condition joint posterior probability distribution of model parameters, you can use it to make predictions for new data.  You can get prediction error estimates by using the new data and making random draws from  the posterior density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's reasonable ask why go to what appears a lot of effort when it would be easier to just use conventional methods?  The answer has many parts.  \n",
    "\n",
    "First, Bayesian modeling methods can be used to estimate where it's not possible to use non-Bayesian methods.  Bayesian models can have many thousands of parameters.  They can be thought of as \"big parameter space\" models.\n",
    "\n",
    "Second, Bayesian estimates are _shrinkage_ estimates, so that they tend to mitigate overfitting by models.  \n",
    "\n",
    "Third, they permit incorporating _prior knowledge_ into the estimation of parameters given data. If there's a lot of prior uncertainty about a parameter, you use a relatively uniformative prior for it. \n",
    "\n",
    "Fourth, hypothesis testing doesn't require relying on asymptotics as sample sizes to to infinity, or to doing thought experiments using imaginary data.  You just use the posterior densities.  \n",
    "\n",
    "Fifth, once you've estimated parameter chains, you can use them to compute posterior distributions of _functions_ of the parameters.  \n",
    "\n",
    "Sixth, parameters for individual observational units can be estimated even when the unit-level data are sparse due to the \"partial pooling\" of information that hierarchical models afford.\n",
    "\n",
    "Lastly, Bayesian methods allow a \"natural\" way of dealing with missing values.  You just estimate them as parameters are estimated, all together in the same simulation."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
